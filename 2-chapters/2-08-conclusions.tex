\chapter{Conclusions and perspectives}
\label{chapConclusions}

\section{Conclusions}
In this thesis, we propose to build better GP regression models by integrating the prior knowledge of Aircraft design with experimental data. Due to the high cost of performing experiments on physical systems, designing them purely through experimentation becomes a costly exercise. Thus models become an obvious means to designing physical systems. Traditionally, these models were built by research institutes, through iteratively performing experiments in a controlled environment. A more cost effective method of building models is by using machine learning algorithms, which infer patterns from data and can be used to perform interpolation and extrapolation. 

Unfortunately in aircraft design, generating a huge amount of accurate data is a costly exercise, for example a high fidelity CFD simulation runs for weeks \cite{murthy2014computational, jameson2012computational, forrester2008engineering} and a flight-test campaign costs millions of euros \cite{fox2004test}. On another hand due to centuries of research and tinkering, we have a treasure trove of prior information about the physical systems. We propose to build better machine learning models by integrating the time-tested prior knowledge of aircraft systems with experimental data. A model generated from merging of the two methodologies will be both consistent with the physics of the system and be quicker to evaluate. 

We demonstrate how to incorporate the prior information by mainly changing the covariance functions of the GP. Prior information in terms of smoothness (section \ref{subSecCh4SEKernel}), linearity (section \ref{subSecCh4LinearKernel}), differentiability (section \ref{subsecCh4MaternKernel}), etc. can be easily encoded using simple covariance functions. Similarly, relationships between multiple outputs can be learned or enforced by treating the `output number' as an extra dimension, this enables us again to easily create covariance functions for MTGPs. A limitation of GPs is that they scale very poorly with data, we provide approximate methods in chapter \ref{chapScalingGPR} and \ref{sec:sparseGPRegression} to help scaling the GP regression to large data-points.

\subsection{Pattern}\label{subsecPattern}
\textbf{How to add \textit{apriori} information of a pattern in a learning algorithm? } \\
Part \ref{partIncorporatePattern} of the thesis concentrates on answering this questions. Chapter \ref{chapBasicCovarianceKernels} shows a few basic kernel types, while chapter \ref{chapCombiningBasicCovariances} shows how to combine these basic kernels together and incorporate more complex patterns. 

The main contribution of chapter \ref{chapBasicCovarianceKernels} is demonstration on how to use GP regression to automatically detect modal parameters of structural dynamics. Using the spectral mixture kernels we demonstrate how to build models for structural dynamic experiments and automatically identify dynamic parameters such as modal frequency. To the best of our knowledge, such a method has not been used in the earlier literature to identify modal parameters. This is a very early stage of application of Spectral Mixture Kernel for system identification, and there remain problems such as identification of mode-shape, and damping ratio in this algorithm. 

Chapter \ref{chapCombiningBasicCovariances} demonstrates how to make new kernels by combining basic covariance functions. This chapter demonstrates how to identify onset of non-linear behaviour in physical systems by using a change-point kernel. For example we identify the initiation of flow separation in NACA 0012 airfoil and initiation of plasticity in AL6061 alloy using a statistical criteria for automatic detection of non-linearity (section \ref{subsubsecCh4ApplicationCP}) \cite{chiplunkar:hal-01555401}. We then use multi-dimensional kernels to build a GP model to predict the position of aerodynamic shock in the transonic regime (section \ref{subecInterpolationOfAerodynamicPressures}) \cite{oatao18004}. The predicted position and accuracy of shock is better than the state-of the art models. 

\subsection{Multiple outputs}\label{subsecSimulationModel}
In the current part (part \ref{partIncorporateMultipleOutputs}) we are interested in learning relationships between multiple outputs. Performing regression on multiple-outputs can be split into two categories, first when we wish to discover relationships across multiple outputs, and second when we wish to enforce a known relationship between outputs (as a bias) into our learning algorithm. Adhering to the main theme of this thesis, we are interested in enforcing a known relationship between outputs into our model. 

\textbf{How to merge \textit{apriori} information of simulations with experiments?} \\
The chapter \ref{chapMultiTaskExtrapolation} proposes a method to extrapolate experimental data in the presence of simulation models. Multi-fidelity models in GPs were first introduced by \cite{kennedy2000predicting} and have been popular in making cost effective surrogate modelling of simulation codes. This chapter demonstrates how multi-fidelity GP models can be used to perform model updating or extrapolation of experimental data. We include an error term and a translation term into a normal multi-fidelity model to account for differences in the simulation model and experimental data. 

\textbf{How to add \textit{apriori} information of relationships between measurements?} \\
Chapter \ref{chapAddingEquationsInGP} tackles the above question by creating MTGP models correlated through physical laws of the system. These physical laws have been developed after centuries of observations and iterative experiments. This chapter extends the framework of gradient enhanced kriging to integral enhanced kriging, quadratic enhanced kriging or any functional relationship between outputs \cite{Constantinescu2013}. 

We first look at how to enforce physical laws which are in the form of linear operators, and then look at approximate methods to enforce physical laws which are in the form of non-linear operators. For both the type of relationships we provide a novel graphical interpretation for the regression process. The improvement in model accuracy is validated on both on a toy dataset and a dataset of real flight-test (section \ref{sec:results}). 

\subsection{Scaling up GPs}
Calculating the precision matrix ($[\myMatrix{K_{XX}}+ \sigma_{noise}^{2}\myMatrix{I}]^{-1}$) is an important task in choosing appropriate hyper-parameters and calculating the posterior mean and variance. Unfortunately, this task has a computational complexity of $\mathcal{O}\left ( N^{3} \right )$ and memory footprint of $\mathcal{O}\left ( N^{2} \right )$. This puts an upper limit of $N \sim 10^4$ on the number of data points. 

This problem is further aggravated when we are creating a joint Gram matrix between several outputs. If we have $D_{outputs}$ each containing $N$ data points, then calculating the precision matrix for an MTGP has a computational complexity of \(\mathcal{O}\left ( (N  D_{outputs})^{3} \right )\) and memory footprint of \(\mathcal{O}\left ( (N  D_{outputs})^{2} \right )\). In the certification phase of aircraft design, we have access to millions ($N \sim 10^6$) of training data points on hundreds of outputs, thus there is a strong need to scale up GPs and MTGPs.  

Chapter \ref{chapScalingGPR} demonstrates how to scale single output GPs. There are two main methods available for scaling up GPs. Sparse methods use Nystr\"{o}m approximation rewriting the Gram matrix, thereby reducing the computational complexity to $\mathcal{O}(NM^{2})$ (M $\ll$ N), $M$ being the number of inducing points. This approximation pushes the limit of GP Regression to $N \sim 10^6$ data points. Distributed GPs distribute the GP Regression tasks into several experts, thereby reducing the computational complexity to $\mathcal{O}(NP^{3})$ (P $\ll$ N), $P$ being the number of points in an expert. This enables to scale GPs to any number of data-points. 

We demonstrate the capability of scaling, by building a distributed GP model for interpolating pressures on millions of nodes in a CFD mesh. To the best of our knowledge this scale of GP model has not been created before for the whole CFD mesh. This surrogate model was used in a recent Airbus flight test campaign to compare pressures predicted from a high-fidelity CFD computation to pressures measured on the wing, in real time.

Chapter \ref{sec:sparseGPRegression} demonstrates how to scale up MTGPs to large number of outputs, both using a sparse approximation (section \ref{sec:varMOGP}) and a distributed GP approximation (section \ref{sec:dMOGP}). We then validate the scalability on a toy dataset and a dataset from flight test and compare the accuracy of distributed GP and variational inference on the toy-dataset. 


\section{Perspectives}
Several future paths can be explored by merging prior knowledge of aircraft design with GP regression. We can incorporate several other patterns available in engineering design to create a GP regression model. These GP models can then be used for \textbf{system identification} (as demonstrated in section \ref{subSecSMKernelApplication}) or \textbf{system control} \cite{kocijan2016modelling, frigola2014variational, deisenroth2011pilco}. Similarly, by incorporating prior patterns we can create more \textbf{accurate surrogate models} when compared to state of the art techniques, these surrogate models can be then used as cheap replacements to more costly simulation codes. 

The capability to integrate multiple outputs correlated through a prior known relationship opens other options for future research. Merging simulation model with experimental data is recurring theme in several verification and validation problems. Multi-output GPs provide a different way to merge these two outputs, leveraging the prior knowledge of simulation model in presence of \textbf{non-separable} differences should be studied in detail. Moreover, by enforcing physical laws in a surrogate model, we can develop schemes to perform \textbf{cheap MDO}, automatically \textbf{detect faulty sensors} and enforce \textbf{inequality constraints}. 

There are several reasons why GPs should be preferred to perform regression tasks. GPs provide a probabilistic framework to define a family of functions, while the covariance functions allows to incorporate a wide range of assumptions (part \ref{partIncorporatePattern}). GPs are computationally tractable, given a covariance function and observations, the predictive distribution can be calculated exactly. GPs are an efficient method to retain the uncertainty arising from prior assumptions and discontinuous data. By providing a closed form expression of marginal likelihood GPs provide a powerful method to automatically select hyperparameters. Although GPs suffer in presence of large data sets, there exist several approximate methods to scale GPs to millions of data points. Moreover, as demonstrated throughout this thesis, their accuracy can be further improved by easily adding prior information of the physical systems.